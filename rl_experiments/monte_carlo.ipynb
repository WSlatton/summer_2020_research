{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte-Carlo Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Blackjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_policy_action(policy, state):\n",
    "    action_distribution = policy[state]\n",
    "    action = random.choices(\n",
    "            list(action_distribution.keys()),\n",
    "            action_distribution.values()\n",
    "        )[0]\n",
    "    return action\n",
    "\n",
    "card_values = {\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "    '6': 6,\n",
    "    '7': 7,\n",
    "    '8': 8,\n",
    "    '9': 9,\n",
    "    '10': 10,\n",
    "    'A': 11\n",
    "}\n",
    "\n",
    "card_weights = {\n",
    "    '2': 1,\n",
    "    '3': 1,\n",
    "    '4': 1,\n",
    "    '5': 1,\n",
    "    '6': 1,\n",
    "    '7': 1,\n",
    "    '8': 1,\n",
    "    '9': 1,\n",
    "    '10': 4,\n",
    "    'A': 1\n",
    "}\n",
    "\n",
    "def draw_card():\n",
    "    cards = card_weights.keys()\n",
    "    return random.choices(list(card_weights.keys()), weights=list(card_weights.values()))[0]\n",
    "\n",
    "def simulate_episode(initial_state, initial_action, policy):\n",
    "    dealer_showing, player_sum, usable_ace = initial_state\n",
    "    dealer_hidden = draw_card()\n",
    "    is_initial = True\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = [None]\n",
    "\n",
    "    while player_sum <= 21:\n",
    "        state = dealer_showing, player_sum, usable_ace\n",
    "        states.append(state)\n",
    "        action = None\n",
    "        \n",
    "        if is_initial:\n",
    "            action = initial_action\n",
    "            is_initial = False\n",
    "        else:\n",
    "            rewards.append(0)\n",
    "            action = get_policy_action(policy, state)\n",
    "        \n",
    "        actions.append(action)\n",
    "        \n",
    "        if action == 'stick':\n",
    "            break\n",
    "        elif action == 'hit':\n",
    "            next_card = draw_card()\n",
    "            \n",
    "            if next_card == 'A' and player_sum + 11 <= 21:\n",
    "                usable_ace = True\n",
    "            \n",
    "            player_sum += card_values[next_card]\n",
    "            \n",
    "            if player_sum > 21 and usable_ace:\n",
    "                player_sum -= 10\n",
    "                usable_ace = False\n",
    "                \n",
    "    if player_sum > 21:\n",
    "        rewards.append(-1)\n",
    "        return states, actions, rewards\n",
    "    \n",
    "    dealer_sum = card_values[dealer_showing] + card_values[dealer_hidden]\n",
    "    \n",
    "    while dealer_sum < 17:\n",
    "        next_card = draw_card()\n",
    "        dealer_sum += card_values[next_card]\n",
    "    \n",
    "    if dealer_sum <= 21 and player_sum < dealer_sum:\n",
    "        rewards.append(-1)\n",
    "    elif player_sum > dealer_sum:\n",
    "        rewards.append(1)\n",
    "    else:\n",
    "        rewards.append(0)\n",
    "    \n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('7', 0, False), ('7', 5, False), ('7', 8, False), ('7', 18, False)],\n",
       " ['hit', 'hit', 'hit', 'stick'],\n",
       " [None, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards = list(card_values.keys())\n",
    "nonterminal = [(dealer_showing, player_sum, usable_ace) for dealer_showing in cards for player_sum in range(22) for usable_ace in [True, False]]\n",
    "initial_policy = {}\n",
    "\n",
    "for state in nonterminal:\n",
    "    dealer_showing, player_sum, usable_ace = state\n",
    "    action = None\n",
    "    \n",
    "    if player_sum <= 17:\n",
    "        action = {'stick': 0, 'hit': 1}\n",
    "    else:\n",
    "         action = {'stick': 1, 'hit': 0}\n",
    "            \n",
    "    initial_policy[state] = action\n",
    "\n",
    "simulate_episode(('7', 0, False), 'hit', initial_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(f, xs):\n",
    "    max_f = float('-inf')\n",
    "    max_x = None\n",
    "    \n",
    "    for x in xs:\n",
    "        y = f(x)\n",
    "        if y > max_f:\n",
    "            max_f = y\n",
    "            max_x = x\n",
    "    \n",
    "    return max_x\n",
    "\n",
    "def monte_carlo_es(initial_policy=initial_policy, iters=10):\n",
    "    policy = initial_policy\n",
    "    action_values = defaultdict(lambda: 0)\n",
    "    times_encountered = defaultdict(lambda: 0)\n",
    "    \n",
    "    for _ in range(iters):\n",
    "        initial_state = random.choice(nonterminal)\n",
    "        initial_action = random.choice(['stick', 'hit'])\n",
    "        states, actions, rewards = simulate_episode(initial_state, initial_action, policy)\n",
    "        T = len(rewards) - 1\n",
    "        returns = 0\n",
    "        discount_factor = 1\n",
    "        \n",
    "        for t in range(T - 1, -1, -1):\n",
    "            returns = discount_factor * returns + rewards[t + 1]\n",
    "            state = states[t]\n",
    "            action = actions[t]\n",
    "            \n",
    "            if not (state, action) in list(zip(states, actions))[:t]:\n",
    "                n = times_encountered[state, action]\n",
    "                times_encountered[state, action] += 1\n",
    "                action_values[state, action] = (n * action_values[state, action] + returns) / (n + 1)\n",
    "                best_action = argmax(lambda action: action_values[state, action], ['stick', 'hit'])\n",
    "                \n",
    "                for action in ['stick', 'hit']:\n",
    "                    if action == best_action:\n",
    "                        policy[state][action] = 1\n",
    "                    else:\n",
    "                        policy[state][action] = 0\n",
    "                \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = monte_carlo_es(iters=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f88ec7ea3a0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0.5, 11.5)\n",
    "y = np.arange(-0.5, 22.5)\n",
    "z = np.zeros((22, 10))\n",
    "\n",
    "for i in range(len(x) - 1):\n",
    "    for j in range(len(y) - 1):\n",
    "        action = policy[cards[i], j, False]\n",
    "        if action['stick'] > action['hit']:\n",
    "            z[j, i] = 1\n",
    "        else:\n",
    "            z[j, i] = 0\n",
    "            \n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
